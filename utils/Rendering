import numpy as np
import matplotlib.pyplot as plt
import cv2
import torch
import os
from tqdm import tqdm

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def PositionalEncoding(x, L):
    
    gamma_x = []
    for i in range(0, L+1):
        gamma_x.append(torch.sin(2**i * np.pi * x))
        gamma_x.append(torch.cos(2**i * np.pi * x))
        
    return torch.cat(gamma_x, axis=-1)
        

def raygen(H, W, focal_length, T):
    """
    Generates rays for rendering.

    Args:
        H (int): Height of the image.
        W (int): Width of the image.
        focal_length (float): Focal length of the camera.
        T (torch.Tensor): Transformation matrix of the camera.
        N (int): Number of rays to generate.
        t_n (float, optional): Near clipping distance. Defaults to 2.
        t_f (float, optional): Far clipping distance. Defaults to 6.
        N_rand_rays (int, optional): Number of random rays to generate. Defaults to None.
        n_frequencies (int, optional): Number of frequencies for stratified sampling. Defaults to 4.
        rand (bool, optional): Whether to generate random rays. Defaults to False.

    Returns:
        points and samples
    """
    # Function implementation goes here
    
    rotation_matrix = T[:3, :3]
    translation_vector = T[:3, 3]
    
    xs = torch.linspace(0, H-1, H).to(device)
    ys = torch.linspace(0, W-1, W).to(device)
    
    x, y = torch.meshgrid(xs, ys)
    
    x, y = x.t(), y.t()
    
    X = (x-H/2)/focal_length
    Y = (y-W/2)/focal_length
    
    rays = torch.stack([X, -Y, -torch.ones_like(X)], axis=-1)
    
    rays = rays.view(H, W, 1, 3)
    
    
    
    
    #change them to world coordinates
    
    rays = torch.matmul(rays, rotation_matrix.t())
    
    # Normalizing the vectors to be unit vectors
    rays = rays / torch.norm(rays, dim=-1, keepdim=True)
    
    rays = rays.view(H, W, 3)
    origin = torch.broadcast_to(translation_vector, rays.shape)
    
    return rays, origin

def pointsgen(rays, origin, N, t_n, t_f, L):
    
    ts = torch.linspace(t_n, t_f, L).to(device)
    
    pts = origin[..., None, :] + rays[..., None, :] * ts[..., None]
    pts = pts.view(-1, 3)
    encoded_pts = PositionalEncoding(pts, L)
    
    return encoded_pts, ts


rays, origin = raygen(10, 10, 1, torch.eye(4))

encoded_pts, ts = pointsgen(rays, origin, 10, 2, 6, 10)

    
    
    
    
    

    
    
    
    
    
    
    
    
    